[TOC]

# 第一章：docker基础

参考：[微信公众号](https://mp.weixin.qq.com/s/bcafrpR21PAr71mBJb6iFw)

**docker的优点**

1、资源利用率比传统虚拟机高

2、支持跨节点部署

3、版本可控，组件可服用

4、共享镜像

5、轻量级，易维护

**docker的缺点**

1、宿主机资源没有完全做到隔离

2、语言不成熟

## 1、安装docker

docker官网建议使用Ubuntu操作系统作为宿主机，应该看重了Ubuntu默认支持AUFS文件系统的缘故。linux内核最小版本是3.10，必须是64位操作系统，

``` shell
#centos上安装docker
yum install -y yum-utils device-mapper-persistent-data lvm2		#安装依赖包
yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo	#添加阿里yum源
yum makecache fast	#更新yum缓存
yum -y install docker-ce	#安装docker
systemctl start docker		#启动docker
docker run -itd -p 80:80 --name webserver nginx  /bin/bash   #启动一个容器,先从本地仓库查找镜像,如果没有再从官网上查找

# 第二种方式，使用docker的离线安装docker，yum可以帮助我们安装依赖
yum localinstall -y docker-ce-17.09.1.ce-1.el7.centos.x86_64.rpm

#Ubuntu上安装docker
wget -qo- https://get.Docker.com/ | sh		#使用wget获取docker安装包，更新docker也是一样

```

**Windows上安装docker：** [参考1：菜鸟教程](https://www.runoob.com/docker/windows-docker-install.html) 

**卸载docker**

``` bash
#centos上卸载docker
yum remove docker-ce		#卸载docker
rm -rf /var/lib/docker		#删除docker保留的数据

#Ubuntu上卸载docker
apt-get purge lxc-Dcoker	#卸载docker
apt-get autoremove --purge lxc-docker	#卸载docker安装包和依赖的模块
rm -rf /var/lib/docker		#删除docker所保留的数据
```

**配置docker**

通常情况下docker默认的参数就可以了，如果想对docker定制化安装，就需要配置docker。

1、创建docker组

默认情况下docker会监听本地的socket文件，这个文件是root用户创建的，其他用户没有读写权限，我们创建一个docker组，然后将docker用户加到docker组里，这样可以回避掉socket文件没有读写权限的问题

```bash
groupadd docker
usermod -aG docker ubuntu	#创建用户到组
```

2、调整内存参数

```bash
#在使用docker中，可能出现类似下面的告警，启动系统中内存和swap统计功能后可以解决
warning :your kernel does not support cgroup swap limit
warning :your kernel does not spport swap limit capabilities limitation discarded
#解决方法：
#1.编辑/etc/default/grub文件
#2.修改 GRUB_CMDLINE_LIUNX 参数如下：

GRUB_CMDLINE_LIUNX="cgroup_enable=memory swapaccount=1"

#3.然后执行 sudo update-grub 更新grub，最后重启系统。
```

3、调整ufw（Ubuntu系统上的防火墙）参数

如果想从另一台机器访问这台主机上的容器，就需要允许外来的请求，docker daemon默认的服务tcp端口是2375.加密的端口是2376

## 2、使用镜像

[关于docker的基本命令可以参考菜鸟教程](<https://www.runoob.com/docker/docker-command-manual.html>)

``` dockerfile
docker pull ubnutu			#从互联网上下载一个镜像到本地仓库,默认使用latest这个标签
docker push  注册用户名/镜像名		#推送镜像到远程镜像仓库
docker search php				#默认从官网查找php的镜像
docker images					#列出本地镜像
docker inspect nginx:latest          #获取docker镜像的详细信息
docker inspect -f '{{.NetworkSettings.IPAddress}}' mynginx           #获取在运行的mynginx容器IP
docker rmi ubuntu:latest             #删除本地仓库的镜像，如果正在使用可加上 -f 强制删除但不建议使用
Docker rmi $(docker images -a|grep none|awk '{print $3}')  #删除没有打tag的镜像
docker rmi $(docker images | grep gcr|awk '{print $1":"$2}')	#删除gcr开头的docker镜像
```

## 3、镜像迁移|导入和导出

```dockerfile
docker save nginx:latest > nginx.tar.gz		#将镜像导出来，就是指保存到本地
docker save -o nginx.03.tar nginx:latest	#或者使用这个命令
#-----------------------------------------------------------------------------
docker load < nginx.tar.gz		#将导出的镜像重新导入镜像库
docker load -i nginx.tar.gz		#或者使用这个命令
```

## 4、docker Hub介绍

官方提供的镜像仓库网址：https://hub.docker.com/

```bash
docker login -u user -p password server_url		#登陆docker Hub
docker logout localhost:8080		#退出
```

直接输入 docker login 也可以登录 默认登陆的是https://hub.docker.com/

## 5、搭建私有镜像仓库

### 5.1、docker开源的镜像分发工具--docker Registry

部署方式参考：<https://www.cnblogs.com/Eivll0m/p/7089675.html>  https://www.cnblogs.com/feinian/p/7857430.html

GitHub网址：https://hub.docker.com/_/registry/

Docker registry 是用于打包，传输，存储和分发的工具

1、安装docker-registry

docker run -d -p 5000:5000 --restart=always --name registry -v /opt/registry:/var/lib/registry registry:2

服务启动之后就可以向她推送和拉取镜像了

### 5.2、harbor部署

 需要基于docker环境，因为我们使用docker来启动harbor镜像库，所以需要先安装docker

创建docker配置文件

```bash
mkdir /etc/docker && vi /etc/docker/daemon.json
```

修改daemon.json文件中的内容

```json
# data-root: docker的数据目录，务必保证目录存在
# hub.paas: harbor镜像库域名
#192.168.191.166: harbor镜像库IP

{
        "log-driver": "journald",
        "data-root": "/home/docker_data_dir",        
        "insecure-registries": [
        "hub.paas",
        "192.168.191.166",                           
        ]
}
overlay2
{
        "storage-driver": "overlay2",
        "storage-opts": "overlay2.override_kernel_check=true",
        "log-driver": "journald",
        "data-root": "/home/docker_data_dir",
        "insecure-registries": [
        "hub.paas",
        "192.168.191.166"
        ]
}

```

```bash
# 启动docker
systemctl daemon-reload
systemctl start docker
```

**1、安装harbor**

```bash
# 解压harbor压缩包并且进入harbor文件夹
tar -zxvf harbor-offline-installer-v1.3.0-rc4.tgz && cd harbor
# 修改harbor.cfg文件如下图
vi harbor.cfg
```

修改harbor的配置文件

```bash
# 将docker-compose（二进制文件）放到宿主机上
cp docker-compose /usr/local/bin/
chmod +x /usr/local/bin/docker-compose
#启动harbor
./install.sh --with-clair
# 安装成功之后，即可通过harbor镜像库的ip地址，通过游览器来访问.初始账号密码为：admin/Harbor12345
```

第二种方法参考：

**1、安装docker-compose**

版本下载地址：https://github.com/docker/compose/releases/

二进制安装：

curl -L https://github.com/docker/compose/releases/download/1.16.1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose

chmod +x /usr/local/bin/docker-compose

**2、根据自己的情况决定是否安装命令补全功能**

yum install bash-completion

或者

curl -L https://raw.githubusercontent.com/docker/compose/1.16.1/contrib/completion/bash/docker-compose -o /etc/bash_completion.d/docker-compose

检查是否安装成功

docker-compose --version

其他安装方式docker-compose

yum install python-pip

pip install  docker-compose

**3、安装harbor**

在线安装的方式

wget -P /usr/loca/src/     https://github.com/vmware/harbor/releases/download/v1.2.0/harbor-online-installer-v1.2.0.tgz

离线安装的方式

https://github.com/vmware/harbor/releases       #下载地址

tar -zxvf harbor-1.7.5.tar.gz

cd /usr/local/harbor/

修改配置文件

1.harbor.cfg

---

## 6、容器常用命令

### 6.1、操作命令

```bash
docker create debian:jessie		#创建容器但不启动
docker restart start stop  容器ID		#重启 启动 关闭 创建的容器
docker run -it debian:jessie /bin/bash		#运行容器,通过bash进入debian系统,退出容器后会关闭. 
docker run -p 3306:3306 --name mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql	#启动mysql容器
docker run --restart=always -itd centos:latest /bin/bash	#后台运行容器,加上--restart=always参数随宿主机一同启动，其他可选参数如下
	-a stdin: 指定标准输入输出内容类型，可选 STDIN/STDOUT/STDERR 三项；
	-d: 后台运行容器，并返回容器ID；
	-i: 以交互模式运行容器，通常与 -t 同时使用；
	-t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用；
	-P: (大写)容器的80端口映射到主机的随机端口
	-p: 容器的端口映射到主机的对应端口，例如： -p 80:80 
	-v: 主机的目录映射(挂载)到容器的目录，例如：-v /home/ubuntu/nginx/www:/www
	-h "mars": 指定容器的hostname；
	-e username="ritchie": 设置环境变量；
	-c 或 --cpu-shares：设置容器使用cpu权重；
	-m 或 --memory：设置内存使用限额。例如 -m 200M、--memory 300M；
	--memory-swap：设置内存+swap的使用限额，当-m 200M --memory-swap=300M时，表示容器可以使用200M内存和100Mswap；
	--vm：启动内存工作线程数。例如：--vm 1，启动1个内存工作线程；
	--vm-bytes 280M：每个工作线程分配280M内存；
	--dns 8.8.8.8: 指定容器使用的DNS服务器，默认和宿主一致；
	--dns-search example.com: 指定容器DNS搜索域名，默认和宿主一致；
	--env-file=[]: 从指定文件读入环境变量；
	--cpuset="0-2" or --cpuset="0,1,2": 绑定容器到指定CPU运行；
	--net="bridge": 指定容器的网络连接类型，支持 bridge/host/none/container:<name|id> 四种类型；
	--link=[]: 添加链接到另一个容器；
	--expose=[]: 开放一个端口或一组端口；
	--name: 为容器指定一个名称；
	--restart=on-failure:50	#重启最大次数为50次

docker exec -it CONTAINER ID(容器的ID) /bin/bash		#进入正在运行中的容器
docker attach		#进入正在运行的容器，例如：docker attach --sig-proxy=false mycon
docker rm 容器id		#删除容器
docker kill		#发送信号给容器默认SIGKILL例如：docker kill -s KILL mycon(-s表示向容器发送一个信号)一般用stop,只有容器停不了的情况下用
docker wait		#阻塞到一个容器，直到容器停止运行。例如：docker wait mycon
docker pause		#暂停容器中所有的进程，当容器不需要继续工作但有不关闭就需要暂停容器。 例如：docker pause mycon
docker unpause		#恢复容器中所有的进程。 例如：docker unpause mycon
docker ps		#查看容器的状态
	-a 列出所有容器 包含未运行的
	-l 列出最新创建的容器 
	-n=2 列出最近创建的2个容器 
	-q 仅列出容器ID 
	-s 显示容器大小
docker logs		#查看容器的日志(stdout/stderr)
	-f	#跟踪日志输出,例如：docker logs -f mycon（查看容器mycon的日志输出）
	--since		#显示某个开始时间的所有日志
	-t		#显示时间戳
	--tail	#仅列出最新N条容器日志，例如：docker logs --since="2017-05-01" --tail=10 mycon(查看容器mycon从2017年5月1日后的最新10条日志。）
docker events	#得到docker服务器的实时的事件
	-f		#根据条件过滤事件；例如：docker events -f "image"="mysql:5.6" --since="1466302400" （显示docker 镜像为mysql:5.6 这个时间戳对应的日期之后的相关事件。）
	--since		#从指定的时间戳后显示所有事件;例如：docker events --since="1466302400" （显示docker 在这个时间戳对应的日期之后的所有事件。）
	--until		#流水时间显示到指定的时间为止；
docker port		#显示容器的端口映射，例如：docker port mycon
docker top		#显示容器的进程信息，支持ps参数。例如docker top mycon
docker diff		#显示容器文件系统的前后变化， 检查容器里文件结构的更改。例如：docker diff mycon
docker cp /www/test mycon:/www/		#将主机的/www/test目录拷贝到容器mycon的/www目录下
docker cp mycon:/www /tmp/test		#将容器mycon中的/www目录拷贝到主机的/tmp/test目录中
docker rename 原来容器名 新容器名	#更改容器名
docker history （镜像名的ID）	#显示image层面的文件变更
docker info #显示docker摘要信息，主要用来确认docker信息
docker inspect nginx:latest          #获取docker镜像的详细信息，参考目录2.使用镜像
docker tag centos:latest centos:7.6		 #打镜像版本
docker version		#x显示docker版本信息

docker pull centos	#从docker仓库下载镜像，默认tag:latest
docker push centos:7.6	#上传到docker仓库，需要先使用login登陆docker仓库
docker search centos		#搜索docker镜像

docker login -u (user) -p (password)	localhost:8080(docker仓库地址)
docker logout localhost:8080

```

### 6.2、组件命令

docker提供了3个工具docker-Machine  、docker-Swarm 、docker-Compose，安装docker时默认不提供工具的。如果想要使用的时候需要安装。

**docker-Machine**

能够帮助我们在不同平台中快速安装和统一管理docker程序

**docker-Swarm**

能够帮助我们在管理集群中高效运行。

**docker-Compose**

属于应用层，能够帮助我们在集群中快速部署，管理多个容器组成的项目工具，可以根据负载情况随时扩展。

在linux环境下安装环境要求，必须要先安装docker，docker内核版本不低于1.7.1

[docker compose下载地址](<https://github.com/docker/compose/releases>)   安装方式如下：

```bash
#先安装pip
yum -y install epel-release
yum -y install python-pip

#升级pip
pip install docker-compose --ignore-installed requests

# 安装compose 第一条语句报错执行第二条，执行成功则跳过第二条
pip install docker-compose
pip install docker-compose --ignore-installed requests 
docker-compose -version

url -L "https://github.com/docker/compose/releases/download/1.23.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
给docker-compose执行权限，运行命令：

chmod +x /usr/local/bin/docker-compose


#卸载docker-compose
rm /usr/local/bin/docker-compose
```

## 7、容器导出和导入

容器中的所有更改都是在沙盒环境下,当容器停止后所有的更改都会丢失，如果需要保存修改，可以用docker commit命令，把修改的容器保存成一个新的镜像。

```shell
docker ps -la		# 找到CONTAINER ID 然后使用命令
docker commit -m "ifconfig" c738ec435db3 centos:7.4		#保存成镜像-m参数为镜像层写一条提交信息
docker images		#可以查到刚刚保存的镜像，然后就可以把保存好的镜像迁移到其他环境了
```

**容器的导入和导出：**不管容器是否处于运行的状态，都可以使用docker export命令将容器保存到压缩文件里

```bash
docker ps		#找出需要导出的容器ID （加上-a参考，可以列出所有的容器）
docker export 39ec3c12291d > centos.tar.gz		#导出容器
docker export -o centos.tar.gz 39ec3c12291d		#也可以用这个方式导出容器
#-----------------
docker import centos.tar.gz		#导入容器，导入的容器不是在容器列表里，而是在本地镜像库里
```

## 8、数据卷

为了达到从外界获取文件以及持久化存储文件的目的，docker提出了数据卷的概念，数据卷就是挂载在容器内文件系统中的文件或者目录，当容器退出或者删除之后，数据卷不会受到影响，会依然存在docker中。容器与数据卷的关系，就像linux系统下对文件或目录进行的mount操作。

<!--创建数据卷的方式有很多种，比较常用的就是创建容器的时候一同创建数据卷，使用docker create 或docker run 命令创建容器时 加上 -v参数-->

``` bash
docker run -itd -v /data:/data fce4312d2ece /bin/bash	#通过-v参数指定的 会自动挂载到容器中。
docker run -itd --privileged=true -v /data:/data fce4312d2ece /bin/bash		#解决不能写入的问题需要加参数--privileged=true
docker create --name web -v /html -v /var/log  nginx	#通常情况下挂载多个数据卷到容器，多次使用-v 参数为镜像层写一条提交信息
docker run -itd -v /data:/data:ro fce4312d2ece /bin/bash	#加上ro参数表示只读数据卷
# 使用专有的命令创建数据卷----------------------------
docker volume create --name fan		#然后使用docker create或docker run命令时，使用-v参数<name>:<dest>
docker create  --name web -v /fan:/fan nginx:latest	#name表示数据卷名称,dest表示数据卷挂载到容器中的路径,如果这个目录已经存在,会把原来的目录隐藏起来
docker ps -a #查找到刚创建的容器id
docker start 容器ID #启动容器，然后验证
```

<!-- 报错出现权限拒绝问题参考：https://blog.csdn.net/skh2015java/article/details/82660020 -->

因为数据卷时脱离容器存在的，我们删除或停止容器时，数据卷的数据不会删除。[^已经启动的容器是无法挂载新的外部目录进行的]

```dockerfile
docker volume list	=#查找宿主机中所有存在的数据卷
docker volume rm <volume name>	#删除数据卷
docker rm -v nginx	#删除容器时加上-v参数，随容器一起删除数据卷,只有数据卷没有被其他容器使用的时候，才会将这个数据卷删除，拥有名称的数据卷不会因为使用-v参数而被删除
```

**数据卷容器**

通过挂载宿主机目录的方式实现长久保存数据，这个方法存在弊端，(破坏docker的统一性) 解决这个问题可以用数据卷容器管理数据卷，数据卷容器是专门用于存放数据卷的容器，我们在其他的容器中需要使用数据卷时，就不在把宿主机的目录当做数据卷挂载了，而是从数据卷容器中将数据卷挂载。

**创建数据卷容器**：数据卷容器的创建和普通容器的创建方法一样，使用数据卷容器时无须保证数据卷容器处于运行状态，

```bash
docker create --name myvolume -v /data:/data f32a97de94e1	#创建数据卷容器和创建数据卷方式创建一样
#同个数据卷容器可以绑定多个数据卷,为了更准确的管理数据卷，建议将不同的数据卷容器存放不同的数据卷或者将数据卷分类分别放在不同的数据卷容器中。
docker inspect myvolume | grep data		#查看宿主机与数据卷对应的目录路径
# 数据卷容器只是其他容器与数据卷连接的桥梁，在创建容器时，通过--volumes-from参数可以指定数据卷容器,加上多个--volumes-from参数，就可以同时使用多个数据卷容器
docker run -itd --name nginx --volumes-from myvolume nginx:latest /bin/bash	#创建容器时,加上--volumes-from参数可以挂载指定容器中的所有数据卷,这些数据卷的挂载点,会和数据卷容器的目录一样。
```

**数据的迁移**

要导出数据，需要创建新的容器，并将其连接到有我们数据的数据卷容器上，容器运行后，就可以进入容器执行打包命令，并将导出的数据放置到挂载的宿主机目录上。

```dockerfile
docker run -it --volumes-from myvolume -v $(pwd):/backup --name exporter --rm centos /bin/bash	#进入容器
tar cf /backup/data.tar /data	#打包备份到 data
exit	#退出
#也可以在创建容器时就把容器的启动命令设置为打包数据的命令
docker run -it --volumes-from myvolume -v $(pwd):/backup --rm 3c682e5cd3c5 tar -cvf /backup/data.tar.gz /data #备份数据卷的数据
#当容器启动时tar程序就会把数据卷文件夹中的数据打包到data.tar中，使用了--rm参考，表示容器停止后会自动删除。
```

**恢复导出的数据**

恢复数据之前，我们要创建一个新的容器，挂载宿主机的数据目录，并连接到包含目标数据卷的数据卷容器上，然后运行并进入容器，在容器中解压包。

```
docker run -it --volumes-from myvolume -v $(pwd):/backup --rm centos tar -zxvf /backup/data.tar.gz
```

[关于数据卷的备份和迁移可参考](https://blog.csdn.net/u013870094/article/details/79366542)：https://blog.csdn.net/u013870094/article/details/79366542

## 9、网络介绍

### 9.1、网络访问介绍

在docker中程序访问外网的主机，可以通过docker0(网桥)转发到宿主机的外网网卡上，所以在容器中，我们可以直接访问宿主机能访问的网络。

外部网络与容器进行连接，也必须通过docker0（网桥）的网关，有可能存在多个容器，所以就无法对所有的容器同时进行转发。对于我们想让外部网络访问容器，可以向docker提供接受访问的端口,实现与宿主机的端口绑定。

创建容器时使用参数 -P(大写) 将容器的端口随机绑定到宿主机的端口上。
``` dockerfile
docker run -itd -P nginx	#启动nginx容器
# docker会在宿主机上查找可用的端口,绑定在容器上，相同镜像创建出来的不同容器,即使容器的端口相同，在宿主机上的端口也不会相同
docker ps -l	#列出容器,查看实际绑定到宿主机上的端口
```

创建容器时使用参数-p(小写)实现宿主机和容器之间的端口映射

```shell
docker run -d -p 80:80 -p 443:443 nginx	#后台运行容器并进行端口映射
```

有时候，我们不但需要做端口映射，还希望对外部主机进行限制，通过 -p ip:hport:cport 这种形式。

```shell
docker run -d -p 192.168.10.1:80:80 nginx	#这样映射后，容器只会收到来自主机IP为192.168.10.1的请求
```

有时候，一个容器运行的应用程序，也需要和另一个容器的应用程序进行数据交换，此时，就需要通过容器连接来完成2个容器之间的数据交换。要设置容器间通信，我们可以通过在创建容器时加上 --link 参数来实现。设置容器间通信，只需要指定被连接的容器，并不需要指明被连接容器的端口，也不需要通过-p参数映射端口

我们创建一个mysql容器，并让一个web服务器连接到它

```bash
docker run -d --name mysql mysql		#创建mysql容器
docker run -d -p 80:80 --name myweb --link mysql nginx	#启动一个nginx 连接到mysql容器
```

在某些情况下，被连接的容器名称可能与连接容器内的某些配置重名，对应这样的情况，docker支持容器间使用别名进行连接的方式。

```bash
docker run -d -p 80:80 --name myweb --link mysql:db nignx  #使用--link name:alias 的方式设置被连接的容器，这样定义后，我们在nginx容器中访问mysql容器时就可以使用db作为访问时的主机名
docker exec -it myweb /bin/bash		#进入容器后可以使用 env 命令查看环境变量信息
```

在容器间可进行连接的配置建立之后，可以在容器信息中发现相关条目。可通过 docker inspect 查看。

容器间通信的主要目的并不是实现网络的访问，而是将网络间访问的方式更抽象化，由于宿主机的网络环境并不固定，所以就无法保障docker申请到的网段总是一致的，在这样的情况下，就需要修改容器中访问其他容器所使用的IP地址，但这样做可能就达不到docker快速部署的目的。docker可以通过修改hosts的方式实现一种即简单有无需修改IP地址的方案。使用docker连接其他容器时，docker会在/etc/hosts中添加一条基于容器名称或者别名的条目，这个解析指向正是被连接的容器。

当我们需要在容器中使用被连接容器地址的时候，只使用容器的名称或设置的别名即可。这样就巧妙的利用了域名解析实现了变化的IP到固定的名称的转变。

当我们创建容器并使用容器连接时，docker会在容器中做两件事，一是修改/etc/hosts文件，二是增加相关的环境变量。

docker网络主要有 以下技术实现

network namespace ：实现了网络资源的隔离，对隔离环境提供了网络设备，协议栈，路由表，防火墙，/proc/net目录，/sys/class/net目录，端口表等网络配置和实现。

veth pair：实现了打穿隔离环境的网络传输数据通道，在docker中，他的一端连接到容器中虚拟的网卡上，另一端连接到宿主机中专用的网桥上，通过这种方式实现了docker容器外部网络的互通。

linux bridge：放置在宿主机中的网桥，起到网络交换机的作用，因为容器网络通过veth pair连接到网桥上，所有他能够在容器间转发网络数据。

iptables：用于提供网络数据透传，net等功能，也可以利用他实现docker网络的防火墙等网络安全防护的需求。

通过docker network ls 命令可以查看当前docker中的网络列表，首次使用和安装docker时，docker会自动创建三个默认网络，

设置容器网络的参数：--dns   --net   --add-host  --mac-address

```bash
docker network ls  #通过命令查看会显示容器默认使用的网络。
NETWORK ID          NAME                DRIVER              SCOPE
8df1b44031a1        bridge              bridge              local	#bridge（桥接模式）
59468096be67        host                host                local	#host(主机模式)
8bfdf04b64f2        none                null                local	#none()
```

默认情况下，==创建的容器都会连接到**bridge**这个网络上==，他对应的就是宿主机上的docker0网卡。一旦安装了docker，就可以看到宿主机上创建了docker0网卡。他扮演着网桥的角色。如果想改变容器中使用的网络可以在创建容器中使用 ==--network参数==。

```bash
docker run -it --name centos --network none centos:latest /bin/bash
```

**none 表示不使用网络**，容器如果绑定到none网络上，则不会为容器分配网络地址。

**host 则是直接使用宿主机的网络环境**。宿主机上的所有网络接口将完全对容器开发。

container:<name|id>	复用容器模式，当模式为container时，这个容器将完全复用另外一个容器的网络，如果使用此模式必须加上参数 --net container:(name|id)

```bash
#当有一个绑定localhost地址的容器名为redis，如果另一个容器容器要复用这个容器的网络，需要这样操作
docker run -d --name redis example/redis --bind 127.0.0.1	
#通过redis的网络访问外部网络
docker run --rm -it --net container:redis  example/redis-cli -h 127.0.0.1
```

### 9.2、自定义网络

有时候，我们希望容器某些容器组成小型网络，不让其他容器访问到。就需要为这个容器单独分配网络。将这些容器放入到单独的网络之前，要先创建一个网络供容器连接。==--driver==参数用来指定网络所基于的网络驱动,也可以简写为-d

```bash
docker network create --driver bridge isolated #这样就创建了名为isolated的网络环境，可使用docker network ls查看
```

要使容器和外部通信都正常运行，最关键的就是要保证网络数据转发，也就是ip forward功能正常启动。docker deamon 启动时，我们可以通过 --ip-forward参数来控制docker是否使用ip forward (默认配置是开启的)。所以通常的情况下我们不需要对其专门设置。如果已经开启了对ip forward的支持，但容器仍然无法连接外部网络，可以先检查宿主机系统中的ip forward是否被禁用。然后在查看本机的防火墙。

```bash
[root@fan15 opt]# sysctl net.ipv4.conf.all.forwarding
net.ipv4.conf.all.forwarding = 1		#启动时参数是1，如果是0时 表示ip forward处于禁用状态。
```

### 9.3、管理容器网络

docker提供了4个管理网络的命令，分别如下：

创建网络(docker network create)：

```bash
# --subnet 参数创建一个拥有指定子网范围的网络
docker network create --subnet 192.168.100.1/24 cnet	#使用docker network ls 查看就可以看到创建了cnet网络
```

获取网络列表(docker network ls)，

获取网络信息(docker network inspect)，

删除网络(docker network rm)。

以上都是介绍容器网络的操作，如果要让容器使用指定的网络，可以在创建容器时使用 --network 参数。或者随时通过(docker network connect)命令让容器连接到指定的网络

```bash
docker run -it --network cnet contos	#新创建容器的时候
docker network connect cnet mysql		#将cnet网络连接到名为mysql的容器上，这样容器里就会存在2个网卡，一个bridge自动分配的网络和一个cnet网络
docker network disconnect cnet mysql	#随时将容器的网络断开，就像拔掉网线一样。
```

### 9.4、配置docker0网桥

配置docker0网桥的时候只能在docker启动前进行。

```bash
dockerd --bip=192.168.1.1/24	#设置docker0的IP地址
dockerd --fixed-cidr=192.168.1.0/24		#设置docker0的网段
dockerd --mtu=65536		#设置docker0的最大数据包长度

brctl show		#查看容器和宿主机建立的连接
```

**自定义网桥**：通过brctl和ip命令，可以在宿主机上创建网桥和配置网桥

```bash
brctl addbr ymbr0
ip addr add 192.168.99.1 dev ymbr0
ip link set dev ymbr0 up
ip addr show ymbr0		#查看刚刚创建的网桥信息

#docker没有启动时，可以通过启动docker时加上 -b 或--bridge参考来指定网桥，如果docker已经启动，则需要先停止，然后在替换原有的docker0网桥
dockerd --bridge ymbr0
```

**配置DNS**：在linux系统中与DNS解析相关的主要有3个配置文件，在etc目录下hostname(主机名，主要是在其他主机的网络发现时告知对方自身的名称) , hosts(用于本地域名解析，他的内容就是域名及对应的解析IP) , resolv.conf(提供DNS服务器的列表，当本地解析无效时，会向互联网请求解析时所连接的服务器地址)

docker容器的文件系统是直接基于对应的基础镜像所建立的，这3个文件存在docker镜像中，我们可以在容器运行时使用mount 命令查看

```bash
[root@33f9a73a3f1a /]# mount
overlay on / type overlay (rw,relatime,seclabel,lowerdir=/var/lib/docker/overlay2/l/3NBRROPZ6AUMF6JTRODTA3H667:/var/lib/docker/overlay2/l/FILL3DZP6TINVLBPUYTKSOYEFA,upperdir=/var/lib/docker/overlay2/a38bdc234f5606823feaca99948439de90c83870eeda19d53da1bced473242e0/diff,workdir=/var/lib/docker/overlay2/a38bdc234f5606823feaca99948439de90c83870eeda19d53da1bced473242e0/work)
proc on /proc type proc (rw,nosuid,nodev,noexec,relatime)
tmpfs on /dev type tmpfs (rw,nosuid,seclabel,size=65536k,mode=755)
devpts on /dev/pts type devpts (rw,nosuid,noexec,relatime,seclabel,gid=5,mode=620,ptmxmode=666)
sysfs on /sys type sysfs (ro,nosuid,nodev,noexec,relatime,seclabel)
tmpfs on /sys/fs/cgroup type tmpfs (ro,nosuid,nodev,noexec,relatime,seclabel,mode=755)
cgroup on /sys/fs/cgroup/systemd type cgroup (ro,nosuid,nodev,noexec,relatime,seclabel,xattr,release_agent=/usr/lib/systemd/systemd-cgroups-agent,name=systemd)
cgroup on /sys/fs/cgroup/blkio type cgroup (ro,nosuid,nodev,noexec,relatime,seclabel,blkio)
cgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (ro,nosuid,nodev,noexec,relatime,seclabel,cpuacct,cpu)
cgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (ro,nosuid,nodev,noexec,relatime,seclabel,net_prio,net_cls)
cgroup on /sys/fs/cgroup/devices type cgroup (ro,nosuid,nodev,noexec,relatime,seclabel,devices)
cgroup on /sys/fs/cgroup/perf_event type cgroup (ro,nosuid,nodev,noexec,relatime,seclabel,perf_event)
cgroup on /sys/fs/cgroup/hugetlb type cgroup (ro,nosuid,nodev,noexec,relatime,seclabel,hugetlb)
cgroup on /sys/fs/cgroup/cpuset type cgroup (ro,nosuid,nodev,noexec,relatime,seclabel,cpuset)
cgroup on /sys/fs/cgroup/pids type cgroup (ro,nosuid,nodev,noexec,relatime,seclabel,pids)
cgroup on /sys/fs/cgroup/memory type cgroup (ro,nosuid,nodev,noexec,relatime,seclabel,memory)
cgroup on /sys/fs/cgroup/freezer type cgroup (ro,nosuid,nodev,noexec,relatime,seclabel,freezer)
mqueue on /dev/mqueue type mqueue (rw,nosuid,nodev,noexec,relatime,seclabel)
# /dev/mapper/centos-root on /etc/resolv.conf type xfs (rw,relatime,seclabel,attr2,inode64,noquota)
# /dev/mapper/centos-root on /etc/hostname type xfs (rw,relatime,seclabel,attr2,inode64,noquota)
# /dev/mapper/centos-root on /etc/hosts type xfs (rw,relatime,seclabel,attr2,inode64,noquota)
shm on /dev/shm type tmpfs (rw,nosuid,nodev,noexec,relatime,seclabel,size=65536k)
devpts on /dev/console type devpts (rw,nosuid,noexec,relatime,seclabel,gid=5,mode=620,ptmxmode=666)
proc on /proc/bus type proc (ro,relatime)
proc on /proc/fs type proc (ro,relatime)
proc on /proc/irq type proc (ro,relatime)
proc on /proc/sys type proc (ro,relatime)
proc on /proc/sysrq-trigger type proc (ro,relatime)
tmpfs on /proc/asound type tmpfs (ro,relatime,seclabel)
tmpfs on /proc/acpi type tmpfs (ro,relatime,seclabel)
tmpfs on /proc/kcore type tmpfs (rw,nosuid,seclabel,size=65536k,mode=755)
tmpfs on /proc/keys type tmpfs (rw,nosuid,seclabel,size=65536k,mode=755)
tmpfs on /proc/timer_list type tmpfs (rw,nosuid,seclabel,size=65536k,mode=755)
tmpfs on /proc/timer_stats type tmpfs (rw,nosuid,seclabel,size=65536k,mode=755)
tmpfs on /proc/sched_debug type tmpfs (rw,nosuid,seclabel,size=65536k,mode=755)
tmpfs on /proc/scsi type tmpfs (ro,relatime,seclabel)
tmpfs on /sys/firmware type tmpfs (ro,relatime,seclabel)
[root@33f9a73a3f1a /]# 可以看出这三个文件都是挂载的形式存在的
```

我们在创建容器时指定相关参数，可以对容器内的DNS相关内容进行配置。==通过-h或者--hostname参数==可以配置容器的主机名，这个配置对写到/etc/hostname里。==通过 --dns参数==可以指定新的DNS服务器，这个配置会写入/etc/resolv.cnf

```bash
docker run -it --name centos -h fan centos:latest /bin/bash		#更改容器的主机名
docker run -it --name centos -h fan --dns 8.8.8.8 centos:latest /bin/bash	#指定DNS服务器
```

## 10、dockerfile

为了简化制作镜像的过程，方便在多台机器上共享镜像，docker提供了一种可以通过配置文件创建镜像的方式----使用dockerfile构建镜像，这种方式是将制作的镜像操作全部写入到一个文件中，然后 docker build 命令可以读取这个文件中的所有操作，并根据这些配置创建出相应的镜像。

dockerfile中的内容主要以两种形式出现：注释行和指令行，以#开头的文本是注释行[^注意： 在dockerfile中，并非所有的以#开头的行都是注释行，有一类特殊的参数是通过#开头的行来指定的]，指令行主要分为两部分，行首是INSTRUCTION，即指令的名称，然后是arguments，即指令所接收的参数。指令是不区分大小写，但为了更清晰的分辨指令和参数，指令一般是大写。

```dockerfile
# Comment
INSTRUCTION arguments
# directive=value		#这样的称为解析指令行，主要是提供一项解析dockerfile需要使用的参数。解析指令行很少被用到。
```

下面是一个简单的构建redis镜像的dockerfile，文件名为dockerfile，如果是其他文件名需要 在构建镜像的时候 加上 -f 指定dockerfile文件

```dockerfile
FROM centos:7.4
MAINTAINER fana "17602199364@163.com"

WORKDIR /home

RUN yum install -y wget gcc && \      
        rpm --rebuilddb && \
        yum -y install gcc automake autoconf libtool make && \
        yum -y install net-tools && \
        yum -y install tar && \
        wget http://download.redis.io/redis-stable.tar.gz && \
        tar -xvzf redis-stable.tar.gz && \
        mv redis-stable/ redis && \
        rm -f redis-stable.tar.gz && \
        yum clean all && \
        cd redis && \
        make && make install
        
EXPOSE 6379
ENTRYPOINT redis-server /home/redis.conf
CMD ["redis-server"]
# --------------------------------------------------------------- #
# 第一条指令from centos:7.2.1511 中的form指令，表示我们要构建镜像所基于的镜像，通常情况下我会使用一个系统镜像来构建我们的应用，接下来是linux的命令。表示我们构建镜像是所执行的操作。 
# 因为有make命令，所以要安装   yum -y install gcc automake autoconf libtool make 
# 想要查看ifconfig，所以安装net-tools     yum -y install net-tools
# 利用这个Dockerfile构建镜像命令：
docker build -t centos/redis .	#执行命令后会自动查找当前目录下的dockerfile
docker build -f dockerfile.redis -t redis:001 .	#加上-f指定配置文件，后面 . 是必须要加上的，表示使用当前目录的dockerfile构建镜像
#启动容器： 
docker run -d --name redis -p 6379:6379 redis:001
```

### 10.1、基础指令(FROM,MAINTAINER)

**FROM指令**：指明基础镜像名称

docker的镜像都是在bootfs层上实现的，但是我们不必每次构建镜像都是从bootfs层开始，我们可以直接在其他已经搭建好的镜像上进行修改，FROM指令就是用来指定我们所要构建的镜像是基于那个镜像建立的，==from指令必须作为第一条指令==，不过在一个dockerfile里是允许出现多个from指令的，以每个from指令为界限，都会生成不同的镜像。

FROM指令主要有以下几种格式

```dockerfile
FROM <image>			#第一种
FROM <image>:<tag>		#第二种
FROM <image>@<digest>	#第三种
# tag 和 digest 都是可选的，当不指定这两项时，docker会使用latest这个tag

MAINTAINER fana
```

**MAINTAINER指令** ： 用于提供镜像的作者信息，一般放在FROM命令下面。



### 10.2、控制指令(RUN,WORKDIR,ONBUILD)

控制指令是dockerfile的核心部分，我们可以通过控制指令来描述整个镜像的构建过程

**RUN指令**：构建镜像过程中，我们需要在基础镜像中做很多操作，run指令就是用来给定需要做什么操作的。

RUN指令有两种使用格式

```dockerfile
RUN command param1 param2	#如：RUN mkdir data 这种形式，在构建镜像时，实际上是以shell(/bin/sh)程序来执行操作的，所以基础镜像必须有/bin/sh
RUN ["executbale","param1","param2", ...]	#如：RUN ["/bin/bash","-c","echo hello"] 这种形式可以有效规避在某些基础镜像中没有shell程序，或者用于需要临时切换shell程序的时候,[]中的数据都会按照json字符串的格式解析，只能使用双引号，不能使用单引号或其他符号
```

注意：[^ 在使用RUN指令时，docker排断是否采用缓存构建的依据，是给出的指令是否与生成缓存使用的指令一致，也就是说，本次执行的结果与缓存中不一致，会采用缓存中的数据，而不再执行命令，这可能导致不是我们想要的结果，比如使用RUN apt-get update 时都需要使用最新的结果，可以使用docker build 命令时加上 --no-cache参数的方式解决这个问题]

**WORKDIR指令**：用于切换构建过程中的工作目录。

给出的工作目录可以是绝对目录，也可以是相对目录

```dockerfile
WORKDIR /usr/local	#绝对目路径
WORKDIR local	#如果是相对路径，在切换工作目录时，会参考当前的工作目录进行。

#也可以在workdir指令中使用环境变量
ENV BASEDIR /project
WORKDIR $BASEDIR /www
```

**ONBUILD指令**：这是一条非常特殊的指令，他可以携带别的指令。使用这条指令不会在构建当前镜像时执行，而是在构建其他镜像时使用FROM指令把z这个镜像作为基础镜像时才会执行。简单来说，就是我们在构建子镜像时运行的指令。

```dockerfile
ONBUILD INSTRUCTION arguments	#把我们需要执行的指令放在ONBUILD指令之后就能设置一个构建触发器，当其他dockerfile把这个镜像作为基础镜像并进行构建时，执行完FROM指令之后，设置的ONBUILD指令都将被触发
```

ONBUILD指令，在生成镜像时会写入到镜像的特征列表中，可以使用docker inspect命令看到镜像的构建命令，当子镜像构建完成后，这些指令也都随着消失了。它不会在继承到新构建的镜像中。

### 10.3、引入指令(ADD,COPY)

很多场合下，我们希望将文件加入到即将构建的镜像中，引入指令就可以帮我们实现这个目的。

**ADD指令**：在构建容器的过程中，可能需要将一些软件源码，配置文件，执行脚本等导入到镜像的构建过程，这时可以使用ADD指令将文件从外部传递到镜像内部。

ADD指令有以下两种形式

```dockerfile
ADD <src>... <dest>		#第一种方式 如：ADD hom* /mydir/ 如果我们给出的路径是目录，那么目录本事不会复制到镜像，被复制的是目录的内容
ADD ["<src>", "<dest>"]		#和上面的方式没有太大差别，只是避免文件路径中带有空格的情况。
```

ADD指令可以自动完成对压缩文件的解压，如果我们提供的是能够识别的压缩文件格式，则会自动解压到镜像的目标路径中。

**COPY指令**：dockerfile中还有一种引入文件的方式就是copy，与ADD指令相似

COPY指令二种使用格式

```dockerfile
COPY <src> ... <dest>	# 第一种方式copy 原路径<src>、目标路径<dest>
COPY ["<src>", ... "<dest>"]	#与add指令的规则几乎是一样的。主要区别就是不能识别网址和自动解压。不需要解压的文件可以使用这个指令
```

### 10.3、执行指令(CMD)

执行指令能够通过镜像建立容器时，容器默认执行的命令，我们通常使用这些命令启动镜像中的主要程序

**CMD指令**：docker容器是为运行单独的应用程序而设计的，当docker容器启动时，实际上是对程序的启动。而在dockerfile中，就可以通过CMD指令来创建镜像容器中的主体程序。可以出现多次CMD指令，但只要最后一次CMD命令生效。

CMD指令有三种使用格式

```dockerfile
CMD command param1 param2 ...	#第一种方法：依靠shell命令来执行
CMD ["executable","param1","param2" ...]	#和上面的方法类似，都是取决于是否使用shell程序来执行命令(推荐)
CMD ["param1","param2" ...]		#这种格式 是将参数传给ENTRYPOINT指令
# 需要注意：容器中只会绑定一个应用程序，所以在dockerfile中只能存在一个CMD指令，如果我们填写多个CMD指令，会覆盖掉之前的指令。
```

**ENTRYPOINT指令**：镜像所指定的应用程序在容器运行时，难免需要一些系统服务或者其他程序的支持。我们可以在CMD指令中启动这个服务，但是这样会让启动服务的命令与启动主程序的命令混在一起，ENTRYPOINT指令就是专门用于主程序启动前的准备工作的。

使用ENTRYPOINT指令的方式和CMD指令的方式相似。

```dockerfile
ENTRYPOINT ["executable","param1","param2" ...]	#第一种方式,直接执行程序
ENTRYPOINT command param1 param2 ...	# 使用shell程序来执行。 这两种格式在效果上和CMD是一样的
```

需要注意：当ENTRYPOINT指令被指定时，所有的CMD指令或者通过docker run 等方式的应用程序启动命令，不会在容器启动时执行。而是把这些命令当成参数。所以我们在使用 ENTRYPOINT 时需要特别注意使用的方法。我们应该在避免在使用 ENTRYPOINT指令 时把 CMD指令的形式配置成shell格式，（即：CMD command param ... ）因为这样做，在 ENTRYPOINT 里是以次级命令的方式启动 CMD的shell进程。docker 就不会把容器的生命周期绑定到进程上。可能会造成意想不到的结果。

### 10.4、配置指令(EXPOSE,ENV)

若想对镜像或者通过镜像所创建的容器进行相关的环境或者网络 等配置时，可以通过配置指令来实现。

**EXPOSE指令**：每个容器都有自己的端口系统，相互之间不连通也不共享，容器间的网络通信需要通过docker转接来完成。如果容器的应用程序需要让其他镜像访问到他所提供的端口，就需要显示出对外提供的端口号。我们要生成镜像时对外开放端口，可以使用EXPOSE指令。

EXPOSE指令的使用方法很简单，将需要共享的端口逐个传入即可。

```dockerfile
EXPOSE <prot>
```

需要注意：EXPOSE指令所指定的端口和 docker run 命令中 -p 参数所指定的端口，含义上是有区别的，EXPOSE指令给出的端口，是基于镜像的容器需要敞开的端口，而创建容器时使用的 -p参数指定的端口，是用于建立容器到宿主机外部的端口映射。就是说，要从外部访问容器内程序监听的端口，首先需要通过EXPOSE指令将这个端口标记对外敞开，在根据实际访问的来源进行配置。从其他容器中访问则需要创建该容器时使用 --link 连接到 此容器，从宿主机外部访问则需要创建该容器时使用 -p参数，建立宿主机对外端口与容器端口的转发。

**ENV指令**：在dockerfile中，我们也能指定环境变量，环境变量能够替换dockerfile中其他指令出现的参数，使用ENV指令就能设置dockerfile中的环境变量。

```dockerfile
ENV <key> <value>		#可以指定一个环境变量，在键名之后的数据都会被视为环境变量的值，如 ENV myDog The Dog
ENV <key>=<value>		#这种格式能够一次指定多个环境变量，并且可以使用\进行换行连接 如 ENV myDog="The Dog" myCat=The\ Cat \
```

**LABEL指令**：使用LABEL指令，可以为即将生成的镜像提供一些元数据作为标记，这些标记能够帮助我们展示镜像的信息。

LABEL指令的用法

```dockerfile
LABEL version="1.0"	#在LABEL指令之后，带入我们希望加入的元数据的键值对，如果有多个键值对，可以使用空格分隔他们如下，在键和值中，如果带有空格，可以使用引号，如果数据过长可以使用 \ 进行换行
LABEL "multi.labell"="value" "com.example.vendor"="You Ming" #推荐把所以的标记写到一个LABEL指令中
```

**USER指令**：USER指令用于设置执行用户，我们可以传入用户的名称或UID作为USER指令的参数

```dockerfile
USER nginx
```

**ARG指令** ：在构建过程中，我们有时还需要进行配置或者使用一些变量，ARG指令就是为我们提供了设置变量的方法。ARG指令与ENV指令有很大的不同，ENV指令用于配置环境变量，他的值会影响镜像的编译，也会体现在容器的运行中，需要改变环境变量时，要在容器启动时进行赋值。而ARG指令则只用于构建镜像的过程中，其效果不会作用于基于此镜像的容器，而覆盖参数的方式也是通过docker build 中的--build-arg来进行的

使用ARG的方式

```dockerfile
ARG <name>	#使用这样的形式定义的格式，变量的值是有外部传递过来
ARG <name>=<default>	#这样形式定义的格式，表示我们未提供变量时就使用默认值
```

用法展示

```dockerfile
FROM busybox
ARG user
USER $user
# 上面是示例，当我们真正构建镜像时，使用 --build-arg参数赋值
docker build --build-arg user=root ./busybox
```

**STOPSIGNAL指令**：当我们停止容器时，docker会向容器中的应用程序传递停止信号，我们可以通过STOPSIGNAL指令修改docker所传递的信号

定义的格式

```dockerfile
STOPSIGNAL 9	#linux内核syscall信号的数字表示
STOPSIGANL SIGKILL	#信号的名称表示
```

**SHELL指令**：CMD ENTRYPOINT等指令都是支持以shell形式执行，SHELL指令可以为他们选定shell程序，

SHELL指令的使用格式

```dockerfile
SHELL ["executable","parameters"]	#使用方法
SHELL ["/bin/bash","-c"]	#shell默认使用的是/bin/sh 若要改为/bin/bash，可以使用这个指令
```

### 10.5、特殊用法

除了基本的指令和备注信息，docker中，我们还可以通过一些特殊的使用方法，控制镜像的构建过程。

**环境变量**：通过ENV指令定义环境变量后，就可以在之后的命令中进行环境变量的替换了，环境变量的解析支持 ADD，COPY，ENV，EXPOSE，LABEL，USER，WORKDIR，VOLUME，STOPSIGNAL 这些指令，

普通的环境变量替换方法是使用 “$+变量名”的方式

```dockerfile
ENV variable value
RUN echo $variable	# value
# 也可以使用花括号将变量名包裹起来，
ENV variable value
RUN echo $variable	#value
RUN echo ${variable}_1	#value
# 如果使用的变量 刚好是我们想要使用的内容，可以使用转义符号去除环境变量的解析过程
ENV variable value
RUN echo \$variable 
```

**指令解析**：使用RUN 等指令时，可以通过 \ 来进行命令的换行。但在Windows系统中，目录的分隔符就是 \ 要解决这个问题，就要利用dockerfile中注释的一种特殊用法：解析指令行

解析指令行的一般用法是 ``` # directive = value ```	<!-- 参数名和值分布在登号的两端，参数名是区分大小写，并且参数名与值周围的空格也会被忽略掉。

### 10.6、使用dockerfile构建镜像

使用dockerfile创建apache镜像

```dockerfile
#apache server
FROM centos:latest
RUN yum update -y && \
    yum install vim -y && \
    yum install httpd -y && \
    yum install net-tools -y && \
    yum clean all

RUN sed -i 's/#ServerName www.example.com/ServerName localhost/g' /etc/httpd/conf/httpd.conf

EXPOSE 80

CMD ["/usr/sbin/httpd","-D","FOREGOUND"]
# 构建镜像，执行命令如下
docker build -f dockerfile.apache -t apache:v1 .
```

使用dockerfile 构建nginx镜像

```dockerfile
#nginx1.15.12

FROM centos:latest
ADD *.tar.gz /opt/

RUN yum update -y && \
    yum install vim -y && \
    yum install net-tools -y && \
    yum install gcc gcc-c++ -y && \
    cd /opt/zlib-1.2.11 && ./configure && make && make install && \
    cd /opt/pcre-8.43 && ./configure && make && make install && \
    cd /opt/openssl-1.1.1b && ./config && make && make install && \
    cd /opt/nginx-1.15.12 && ./configure --with-http_ssl_module --with-http_flv_module --with-http_mp4_module --with-http_realip_module --with-http_stub_status_modul
e --with-http_gzip_static_module --with-openssl=/opt/tools/openssl-1.0.2d --with-pcre=/opt/tools/pcre-8.36 --with-zlib=/opt/tools/zlib-1.2.8 --with-pcre && \
    make && make install

EXPOSE 80 443

CMD ["nginx","-g","doemon off;"]
```

使用dockerfile 构建tomcat镜像

```dockerfile
# tomcat server

FROM java:8-jre
RUN apt-get update && apt-get install -y tomcat8
EXPOSE 8080
CMD ["/usr/share/tomcat8/bin/catalina.sh","run"]
```

使用dockerfile 构建mysql镜像

使用dockerfile 构建MongoDB镜像

使用dockerfile 构建redis镜像

```dockerfile
# redis

FROM debian:jessie

RUN apt-get update \
    && bulidDeps='gcc make libc6-dev wget' \
    && apt-get install -y --no-install-recommends $buildDeps \
    && wget -O redis.tgz "http://download.redis.io/releases/redis-3.2.3.tar.gz" \
    && make -p /usr/src/redis \
    && tar -zxf redis.tgz -C /usr/src/redis --strip-components=1 \
    && rm redis.tgz \
    && cd /usr/src/redis \
    && make \
    && make install \
    && cd / \
    && rm -rf /usr/src/redis \
    && apt-get purge -y --auto-remove $buildDeps
EXPOSE 6379
CMD ["redis-server"]
```

使用dockerfile 构建java镜像

```dockerfile
FROM debian:jessie
RUN echo 'deb http://httpredir.debian.org/debian jessie-backports main' > /etc/apt/sources.list.d/jessie-backports.list \
    && apt-get update \
    && apt-get install -y openjdk-8-jre \
    && rm -rf /var/lib/apt/lists/*
CMD ["java","-version"]
```

**paas平台**

```dockerfile
# 天翼云paas平台dockerfile
FROM hub.paas/base/centos-jdk8:maven-ord-v1.6
ADD *.tar.gz /usr/local/ord-biz-rule
EXPOSE 9088
RUN chmod +x /usr/local/ord-biz-rule/bin/run.sh
CMD '/usr/local/ord-biz-rule/bin/run.sh'

#run.sh的脚本的内容如下

#!/bin/sh
appBin=`dirname $0`
cd $appBin
basepath=`pwd`
appLog=$basepath/../log
appConf=$basepath/../conf
appLib=$basepath/../lib
ppPath=$basepath/../pinpointAgent

jpacfg=""

if [ -n "${shtelpaas_jpa_entity_basepkg}" ]; then
jpacfg=" --shtelpaas.jpa.entity.basepkg=${shtelpaas_jpa_entity_basepkg} "
fi

if [ -n "${shtelpaas_jpa_repo_basepkg}" ]; then
jpacfg=${jpacfg}" --shtelpaas.jpa.repo.basepkg=${shtelpaas_jpa_repo_basepkg} "
fi

pinpoint=""

if [ -d "$ppPath" -a -n "${profiler_collector_ip}"  ]; then
#pinpoint文件不支持环境变量，人工替换
sed -i "s/\${profiler_collector_ip}/${profiler_collector_ip}/g" $ppPath/pinpoint.config

if [ -n "${profiler_shtelpaas_pp_enable}" ]; then
    sed -i "s/\${profiler_shtelpaas_pp_enable}/${profiler_shtelpaas_pp_enable}/g" $ppPath/pinpoint.config
else
    sed -i "s/\${profiler_shtelpaas_pp_enable}/false/g" $ppPath/pinpoint.config
fi

if [ -z "${profiler_shtelpaas_pp_joinpoint}" ]; then
    profiler_shtelpaas_pp_joinpoint="profiler.shtelpaas.pp.class.com.shtel.paas.sdk.core.log.PaasLogger._method_.metricInfo=java.lang.String,java.lang.Object[]"
fi
sed -i "s/\${profiler_shtelpaas_pp_joinpoint}/${profiler_shtelpaas_pp_joinpoint}/g" $ppPath/pinpoint.config

if [ -n "${profiler_include}" ]; then
    sed -i "s/\${profiler_include}/${profiler_include}/g" $ppPath/pinpoint.config
else
    sed -i "s/\${profiler_include}//g" $ppPath/pinpoint.config
fi

if [ -n "${profiler_entrypoint}" ]; then
    sed -i "s/\${profiler_entrypoint}/${profiler_entrypoint}/g" $ppPath/pinpoint.config
else
    sed -i "s/\${profiler_entrypoint}//g" $ppPath/pinpoint.config
fi

if [ -n "${pinpoint_agentId}" ]; then
    agentId="${pinpoint_agentId}"
else
    #pinpoint.agentId can only contain [a-zA-Z0-9], '.', '-', '_'. maxLength:24
    agentId=`hostname`${shtelpaas_app_name}
    agentId=${agentId//./}
    agentId=${agentId//_/}
    agentId=${agentId//-/}
    let stIndex=${#agentId}-24
    if [ "${stIndex}" -lt 0 ]; then
    stIndex=0
    fi
    agentId=${agentId:stIndex}
fi

if [ -n "${pinpoint_applicationName}" ]; then
    ppApp="${pinpoint_applicationName}"
else
    ppApp="${shtelpaas_app_name}"
fi

pinpoint="-javaagent:$ppPath/pinpoint-bootstrap-1.6.2.jar -Dpinpoint.agentId=${agentId} -Dpinpoint.applicationName=${ppApp}"
fi

ipinfo=""

if [ -n "${shtelpaas_app_ip}" ]; then
ipinfo="-Dappip=${shtelpaas_app_ip}"
fi

busiCenter=""

if [ -n "${shtelpaas_center_name}" ]; then
busiCenter="-DbusiCenter=${shtelpaas_center_name}"
fi

serviceLayer=""

if [ -n "${shtelpaas_service_layer}" ]; then
serviceLayer="-DservType=${shtelpaas_service_layer}"
fi

dockerId=""

if [ -n "${HOSTNAME}" ]; then
dockerId="-Dpinpoint.dockerId=${HOSTNAME}"
fi

localhostIp=""

if [ -n "${paas_container_host_ip}" ]; then
localhostIp="-Dpinpoint.localhostIp=${paas_container_host_ip}"
fi

e2eAgent=""

if [ -n "${ETE_AGENT_ENABLE}" -a -n "${ETE_AGENT_JAR}" -a -n "${ETE_AGENT_YML}" ]; then
e2eAgent="-javaagent:${ETE_AGENT_JAR}=${ETE_AGENT_YML}"
fi

java ${JAVA_OPTS}  -cp "$appLib/*" -Dlogpath=$appLog -Dappname=${shtelpaas_app_name} ${busiCenter} ${serviceLayer} ${ipinfo} ${dockerId} ${localhostIp} ${pinpoint} ${e2eAgent} com.shtel.paas.sdk.app.PaasMainApp  --shtelpaas.app.name=${shtelpaas_app_name} --shtelpaas.app.basepkg=${shtelpaas_app_basepkg} --shtelpaas.app.config.profile=${shtelpaas_app_config_profile} --shtelpaas.log.profile=${shtelpaas_log_profile}  --shtelpaas.app.nameserver=${shtelpaas_app_nameserver} ${jpacfg}
```

## 11、docker资源限制

==限制容器分配最大内存==，在创建容器时加上参数 -m 或 --memory参数。在设定内存上限需要注意，如果容器进程中出现OOM错误时，docker会强制杀死这些

```dockerfile
docker run -d -m 512M nginx:latest		#限制内存上限为512，但内存+交换分区总量为512*2
docker run -d -m 512M --memory-swap 1024M nginx:latest	#表示允许使用的内存是512m,交换分区+内存是1G,所以容器中允许使用的交换分区是512M。
docker run -d -m 512M --memory-swap -1 nginx:latest /bin/bash #设置docker容器内存为512M,允许使用更多的内存
docker run -it -m 100M --oom-kill-disable nginx:latest /bin/bash	#限制容器内存使用总量，同时关闭oom功能
docker run -it --oom-kill-disable nginx:latest /bin/bash	#没有限制容器内存使用总量，同时还关闭了oom功能，（要慎用，比较危险）
docker run -it --memory-swappiness=0 nginx:latest /bin/bash	#设置权重的值，可在一定程度上提高交互分区工作效率，0表示不允许容器使用，100 表示允许容器使用所有的内存分页，没有设置就会从镜像参数中继承过来
```

在docker里，没有直接使用具体的参数配置而是==通过权重来分配CPU==，使用-c或者--cpu-shares参数设置CPU占用的权重，权重值从0到1024，如果当前主机允许了3个容器，容器A占用cpu权重为1024，容器B和容器C都是512，当3个容器都处于100%使用CPU时，容器A会得到50%，容器B和容器C会各得到25%。

```bash
docker run -d -c 500 nginx:latest /bin/bash	#设置资源占用权重，只是限制实际允许个容器对CPU资源的需求。
docker run -it --cpu-period=50000 --cpu-quota=25000 nginx:latest /bin/bash	#--cpu-period来限制容器的CPU等待周期，进而限制其使用CPU的权重，通常这2个参数要搭配使用
docker run -it --cpuset-cpus="1,3" nginx:latest /bin/bash	#设置容器可以使用CPU的核数，表示可以使用1号和3号CPU，0-2这样表示可以使用 0号 1号 2号 这3个CPU
```

docker可以通过run命令的--blkio-weight参数，取值范围为0-1000,为每个容器读写块设备的I/o资源进行限制，默认情况下容器对I/O限制都是相同的。docker仅支持对块设备的I/O进行限制，不支持其他类型的I/O限制。

```bash
docker run -it --name c1 --blkio-weight 300 ubuntu:14.04 /bin/bash
docker run -it --name c2 --blkio-weight 600 ubuntu:14.04 /bin/bash
```

对于硬盘，可以通过--device-read-bps和--device-write-bps命令限制指定硬盘的读写速度，还有--device-read-iops和--device-write-iops限制IO

```bash

```

创建容器时加上 --ulimit 参数来配置ulimit,可以修改core dump文件大小，数据段大小，文件句柄数，进程栈深度，CPU时间，单一用户进程数，进程虚拟内存等，

```bash
docker run -d --name nginx --ulimit cpu=1000 nginx:latest
docker exec -it nginx /bin/bash		#然后进入容器查看
#执行命令 ulimit -t
docker dockerd --default-ilimit cpu=1000		#这样配置容器默认的Ulimit限制。
```

```dockerfile
docker stats --no-stream centos	#查看容器占用的资源，可以显示CPU,内存，IO，进程数量等情况。类似top命令
```

# 第二章：docker进阶

## 1、docker运行剖析

在docker体系结构中，最重要的组件有3个，这3个的关系，可以说container 是基于image 的 ，但被daemon创建和管理，来实现提供服务的功能。container提供服务，所有处于核心的位置，当我们谈到docker生命周期时，更多的是指docker container的生命周期。

1. docker deamon ：负责维护docker运行的守护进程，担负着资源管理，任务调度等多项功能。
2. docker image（镜像） ：属于静态的文件系统
3. 和docker container（容器）：提供应用服务的计算单元

异常关闭发生的原因有很多，在实际运行当中主要有以下2种情况

1.1、内存溢出（OOM）

为了保持主机环境和docker中各个容器运行稳定性，docker在处理oom事件时采用了 熔断器 和 耐压舱 的处理机制。如果容器中的应用耗尽了主机系统分配给容器的内存限额，就会触发OOM事件，容器会被强制关闭。关闭容器的并非docker daemon 而是宿主机操作系统。因为容器其实就是运行在宿主机的一个进程，宿主机会通过cgroups对这个进程设定资源上限，当这个进程申请的资源达到上限时，就会触发系统内核OOM事件，宿主机内核就会关闭这些进程，这个就是熔断器 机制，只要目标达到一个阀值，就会销毁它。

可以使用参数 --oom-kill-disable来禁用OOM-killer ,使用这个参数需要注意，如果使用 -m 设置了容器的内存上限，当容器达到内存资源上限时，主机不会关闭容器，也不会继续向容器分配资源了，这个时候容器就会处于 hung状态，这种机制就是 耐压舱，如果使用了 --oom-kill-disable 但没有使用 -m 设定上限，这个时候容器就会使用主机的全部内存资源。

1.2、进程意外退出

每个容器内部都存在一个init进程，容器中其他的进程都是此进程的子进程。如果容器中一个子进程由于某种原因造成了退出，那么父进程也会退出，直至init进程也退出，当init进程退出时，容器就会被关闭。与OOM不同的是，docker 目前没有任何机制可以检测到此时的进程属于正常还是异常，当设置了 --restart 参数的容器会尝试重启。

在docker容器的生命周期中，除了running 和 stopped 之外，还有 paused(暂停)，处于此状态的容器，是因为 停止 CPU资源，而内存，网络 等资源 都保留未动，如此一来，失去了CPU资源的进程，是不会被内核所调度。如果想要恢复，只要重新赋予 CPU资源就可以了。因此一个容器的完整生命周期 就是 running --> paused --> stopped 三种状态之间互相转换。

**docker daemon 主要负责哪些事情**

daemon 负责任务调度，他需要将客户端传来的命令请求转化为特定的任务。

daemon 负责维护镜像数据，一个完整的镜像有许多的子文件层组成，而这个镜像的依赖关系就是由daemon来维护的。

daemon 负责容器虚拟化，虚拟化是一个较大的概念，具体来说就是资源分配和资源隔离。

daemon 负责容器生命周期，需要根据用户指令和容器自身状态来维护容器的生命周期。

## 2、docker 内核讲解

在docker之前，需要实现虚拟机 KVM几乎是唯一可选的成熟方案。docker选择了namespaces+cgroupus 实现虚拟化的方案，他们都是软件级的资源隔离和控制，相对于KVM，性能损失最低，资源利用率最高。

### 2.1、docker背后的namespace

docker是借助 mount 、IPC、 network、 PID、 user、 UTS 这6个namespace完成了资源隔离。

==IPC Namespace==：linux 系统中的进程通信方式，主要包括, 信号量，消息队列，共享内存，对应一个隔离的容器，容器内部的所有进程都只能访问主机分配给他的资源，docker自身通信都是通过TCP或者 socket 进行通信的，所以，IPC namespace 并不是为了容器自身使用，更多的是为了容器内部的应用而预留的，如果容器内部运行的应用需要使用 message queue ,就可以在同一个宿主机中创建多个message queue，而不会产生干扰，而后docker容器创建 PID namespace

==PID Namespace==：这个namespace 非常重要，他是容器资源隔离的一个重要标志，就是容器之间的进程树相互不可见，通过PID namespace 每个容器中都有一个进程号计数器，容器内所有的进程号会被重新编号，宿主机的内核维护各个容器的进程树，在树顶端的进程号为1，就是init进程，这个进程会作为容器内其他所有的进程的父进程，来执行容器环境的初始化工作。init作为容器中所有进程的父进程，肩负着关闭和销毁容器。处于树顶点的init进程可以看到容器中所有的子进程，可以通过信号量影响子进程的行为。

容器中的init进程 其实是一个伪init进程，不是实际操作系统中的init进程，无法像真正的init进程那样守护操作系统。当init进程下面所有的子进程都退出后，他也就退出了，这就是每个容器启动时，都需要指定一个不可退出的进程的原因。

通过PID namespace ，docker为容器创建的独立进程资源，但资源完全独立还远不够，因此docker后面就为容器开始创建 UTS namespace

==UTS namespace== ：一个拥有独立进程树的容器，仅能在宿主机层面被视为独立节点，docker还需要在网络层面设为一个独立节点，docker为了实现这个目标，为每个容器都创建了UTS namespace。 

UTS namespace 只设置了容器的主机名和域名，但正因为这2个属性在每个容器中都是独立的 唯一的，因此每个容器在网络中都可以被设为单独节点，而非宿主机的单独进程。

至此，docker创建的容器通过PID namespace 拥有了独立的进程树，通过UTS namespace 作为独立节点而拥有了独立的主机名和域名资源，同时每个容器通过 IPC namespace 可以毫无干扰使用IPC 资源。这些都是我们在进程资源方面完成了独立，还没有在网络层面完成资源独立。（因为我们在容器A中部署tomcat占用了8080端口，在容器中再部署相同的tomcat 同样监听8080端口，就会导致端口冲突，因为在同个宿主机上没有实现网络隔离）

==network namespace== ： docker 通过 network namespace 为每个容器隔离网络资源，一个典型的network namespace 包括 IP 协议栈、IP路由、端口信息和物理网卡，在linux系统中，一个物理设备只能在一个network namespace中，但我们创建的容器却不止一个，docker为了解决这个问题，为每个容器的network创建一对虚拟网络设备，一个名为 eth0, 放在容器中，另一个名为vethN 在宿主机上。虽然从宿主机内核层面来看，只是管道的两端，但从容器来看，就是二块实际的网卡，通过这样的方式，就可以达到容器和内核直接数据流通的目的。但为了达到不同容器可以作为单独节点进行数据交互，docker 在 network namespace中还为每个容器设置了路由表，宿主机就充当路由器的角色了。这样容器拥有了独立的网络资源，虽然是通过宿主机环境的管道机制来完成的数据转发，但我们可以随意使用当前容器的网络资源，监听任意端口和数据通信。

==user namespace==：容器作为独立的操作系统用户资源也必须是独立的，所以有了 user namespace，docker 通过user namespace 隔离了所有与用户相关的资源，包括用户ID，用户组ID，用户权限，但无论容器中的用户怎么变，都是对应的宿主机创建的容器的用户，这种关联是通过/proc/[pid]/uid_map和/proc/[pid]/gid_map这2个文件保存的。

==mount namespace==：为每个容器分配独立的文件系统，在mount namespace中，通过挂载点的方式提供隔离文件系统，因此docker为每个容器创建一个独有的目录，并且将此容器所依赖的镜像文件层按照先父后子的顺序，逐层挂载到此目录中。隔离完成之后，不同的mount namespace之间的数据互不影响，同时docker会将当前目录设置成 read-only（只读）模式。对目录的写操作都体现到另一个目录，就是我们所说的writable。

docker 具有了独立的进程树，独立文件系统，独立网络资源，独立主机名，和独立用户环境，提供的虚拟化属于伪虚拟化，因为资源独立都是建立在供销资源的前提下，比如共享内核，共享内存，共享CPU，共享物理网卡等。

### 2.2、docker的文件系统

当docker daemon 为容器配置好各种namespace参数，准备启动容器时，首先加载的是容器的文件系统，并在此文件系统的基础上运行容器中的操作系统。目前docker中使用最多的是AUFS（一个分层文件系统）他可以将不同的目录挂载到同一个虚拟目录中，并形成文件层。

docker通过AUFS可以达到镜像共享文件层，共享数据的目的。

AUFS将不同的目录挂载到同一个文件系统下时，可以给不同的目录设定 只读，只写，和写读 三种权限，AUFS在挂载目录时，会严格按照先基础目录(父文件层)再增量目录（子文件层）的顺序进程挂载，所有目录都挂载玩之后，AUFS会再挂载一个可读可写的目录，而以后所有的写操作都会在这个目录。

docker 处理 AUFS外，还可以使用 devicemapper、 btrfs、vfs三种文件系统，但AUFS实现起来简单，容易扩展。

### 2.3、docker的image管理

docker默认将所有数据都存储在/var/lib/docker，可以用命令 docker info 查看具体目录





## 3、docker资源调度

docker底层是通过cgroups来管理资源的，cgroups最初叫做 process container后改名为control Groups顾名思义就是吧进程放在一个组里面进行统一控制，

cgroups为资源管理提供统一的框架，可以把系统任务及其子任务整合或分隔，到按资源等级而划分的不同任务组内，并且对这些任务组实施不同的资源分配方案，通俗来说，cgroups可以限制，记录，隔离进程组所使用的物流资源（包括CPU，memory，I/O）

cgroups机制中有四个需要理解的概念

- 任务（task）一个任务对应宿主机环境当中的一个进程。
- 子系统（subsystem）每一个子系统是对某一项具体物理资源的控制器，例如，CPU子系统是对CPU资源的控制，内存子系统是对内存资源的控制。
- 控制组（control group）是最基本的控制单元，一个group包含若干个任务（对应宿主机环境的进程）并且此group也会包含若干子系统，用来控制group内的任务在指定子系统上面的资源使用。
- 层级树（hierarchy）cgroups的调度单位，由一个或多个group组成的树状结构，每个hierarchy通过绑定对应的子系统进行资源调度，同时子节点继承父节点的属性，整个系统可以有多个hierarchy



目前cgroups的子系统：查看 /proc/cgroups 可以查看当前操作系统支持的子系统

- blkio：为块设备。docker使用2种策略：CFQ(完全公平队列策略)，blkio.weight（权重比较）默认是CFQ，既对所有容器一视同仁，不分彼此，如果使用权重比较的策略，内核会适当将 I/O 资源多分给权重大的容器。
- cpuacct：为cgroups中任务生产CPU资源使用报。对应CPU资源，也有2种策略，CFS（完全公平调度策略），RT（实时调度策略）目前docker使用的是CFS策略，通过CPU.cfs_period_us和cpu.cfs_quota_us设定周期和周期内最大可用时间。在通过CPU.shares设定容器使用的CPU权重
- cpuset：在多CPU系统中，为cgroups中的任务分配独立CPU和内存节点。
- devices：设置任务对物理设备的访问权限。可以对具体的设备设置黑名单或白名单
- freezer：挂起或者恢复cgroups中的任务。包括如下三种状态，frozen：暂停。freezing：正在暂停，thawed：恢复。
- memory：设定cgroups中任务使用的内存限制，同时生产任务的内存资源使用报告
- net_cls：使用等级识别符（classid）标记网络数据包，同时使用linux流量控制程序（tc）识别从具体cgroup 中生成的数据包
- net_prio：对应用程序设置网络传输优先级，类似于socket选项的so_priority
- hugeTLB：hugeTLB页的资源控制功能

docker和传统的虚拟机有区别，传统虚拟机中所有的操作都是需要经过内核处理，但这里的内核是指虚拟机内部运行的内核，及时被黑客攻击也只有这一台虚拟机受影响。docker是所有的容器都运行在同一个宿主机内核当中，如果某个容器被黑客攻击，黑客就可以通过这个容器操作内核，控制其他的容器。

针对docker安全来说，就是不对宿主机产生影响，和不对其他容器产生影响。所以docker的安全问题就是资源隔离问题。虽然可以通过namespace将大部分资源相互隔离，但一些重要的资源无法隔离，例如（共享内核，共享硬件设备，共享同一个root用户，共享/proc/sys/等文件系统）共享selinux,time等资源。

docker无法从内核级别完善安全机制，只能依靠某些用户态的一些策略来提高docker安全性。比较成功的有以下几种。

1.capability策略

所有容器在宿主机环境中对应的进程都是以root权限在运行，一旦容器 被黑客攻陷，那么黑客就可以使用root权限操作内核。对于docker来说，不适合的capability列表有可能会导致容器中的应用崩溃，所以用户从功能性，安全性和稳定性入手。通常来说docker创建容器时，所赋予的默认capability列表。基本能满足容器的正常运行。

2.seLinux策略

目前docker还无法将selinux应用于容器中，建议用户在宿主机上启用selinux。

3.缩小用户权限策略



4.使用信任镜像策略

用户所使用的镜像，最好是自己 docker build 生成的，如果需要第三方镜像，建议选择官方版本。

5.CGroups策略



6.最小文件系统策略



## 4、练习

本次实践的目标是搭建一个完整的web服务器，我们采用 nginx + memcached + mysql + PHP的架构，以上镜像我们从docker hup上获取。

**1、启动容器**

```bash
docker run -d --name memcached memcached:latest	#启动memcached
docker run -d --name mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql:latest	#启动mysql，并设置密码123456
# 启动PHP 代码挂载目录时/app,需要让PHP连接到mysql和memcached
docker run -d --name php -v /app:/app --link mysql --link memcached php:latest /bin/bash
# 启动nginx
docker run -d --name nginx -v /app/nginx/nginx.conf:/etc/nginx/nginx.conf -v /app:/app --link php -p 80:80 nginx:latest /bin/bash

```



**2、程序配置**

等程序配置完成后，就可以做基本的测试了





# 第三章：docker生态圈

## 1.docker的开源组件

docker无法从容的应对复杂的场景，需要和其他开源工具一起使用，可以增强docker的开源工具有如下：

### 1.swarm

是docker官方提供的工具，swarm通过调用docker提供的rest API来管理docker集群。

swarm有管理器和代理二部分组成，管理器运行在master节点，其他节点运行swarm代理。目前来说，swarm适合docker集群的初级管理，因为swarm在网络层面非常薄弱。swarm适合作为小规模集群管理。

### 2.kubernetes

是谷歌推出的一个docker容器管理器，kubernetes引入pod（容器仓）的概念，容器仓表示一个被当做单一逻辑服务来部署的容器。非常适合一个容器运行一个服务的部署思想。除了pod，kubernetes还将真实的应用服务抽象成services，每一个services背后有很多对应的pod支撑，每一个service对外表现为一个单一访问接口。

集群规模不超过1万节点的情况下，推荐使用kubernetes来管理集群，如果集群规模达到万级规模的情况下，可以参用mesos方案

### 3.mesos

mesos始终是围绕高可用和弹性进行设计的，所以在一个有mesos管理的集群中，可以运行Hadoop  	spark	 docker

一个典型的mesos集群，一定会有mesos-master	mesos-slave	frameworks和zookeeper 这四部分。master负责收集集群资源，slave负责管理本节点上的任务，frameworks是计算框架，通过mesosSchedulerdiver接入 mesos，zookeeper用于选择和查找当前master地址，为了容错，zookeeper会管理mesos master节点和备master节点，（实际部署中，通常会有2个或者4个备master节点时刻准备接替故障的master节点）

master会维护一个现有的资源列表，并且基于分配策略来觉得提供多少资源然后master将列表提供给frameworks，frameworks由两部分组成，注册到mesos中的调度器（scheduler）和运行在slave节点的任务执行进程（executor）通过这两部分，frameworks可以决定接受多少资源和决定哪个任务使用多少资源。

mesos集群可以运行多个frameworks，以适应不同种类的任务。



# 第五章：docker运维技巧





































